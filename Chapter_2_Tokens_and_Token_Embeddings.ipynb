{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKkktqTWSI9wI1GqHRWL5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish265/hands_on_Large_Language_models/blob/main/Chapter_2_Tokens_and_Token_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRervZvSJd3A"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map='cuda',\n",
        "    dtype='auto',\n",
        "    trust_remote_code=False)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|>\"\n",
        "\n",
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# Generate the text\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=20\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(tokenizer.decode(generation_output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3wed1hwKvxg",
        "outputId": "89749602-641c-4fd3-8f05-1386dab72154"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|> Subject: Heartfelt Apologies for the Gardening Mishap\n",
            "\n",
            "\n",
            "Dear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pW3Z3z6S1fE",
        "outputId": "49442d43-8f5f-47ad-fdf1-72bb308fe5da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14350,   385,  4876, 27746,  5281,   304, 19235,   363,   278, 25305,\n",
            "           293, 16423,   292,   286,   728,   481, 29889, 12027,  7420,   920,\n",
            "           372,  9559, 29889, 32001]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id in input_ids[0]:\n",
        "   print(tokenizer.decode(id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTHSB-3ZS5L0",
        "outputId": "324abecf-64bd-422b-a872-f525f17aa913"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write\n",
            "an\n",
            "email\n",
            "apolog\n",
            "izing\n",
            "to\n",
            "Sarah\n",
            "for\n",
            "the\n",
            "trag\n",
            "ic\n",
            "garden\n",
            "ing\n",
            "m\n",
            "ish\n",
            "ap\n",
            ".\n",
            "Exp\n",
            "lain\n",
            "how\n",
            "it\n",
            "happened\n",
            ".\n",
            "<|assistant|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmDstaZrUTNx",
        "outputId": "be7de02f-f2d8-4dac-f523-e784109bdb65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14350,   385,  4876, 27746,  5281,   304, 19235,   363,   278, 25305,\n",
              "           293, 16423,   292,   286,   728,   481, 29889, 12027,  7420,   920,\n",
              "           372,  9559, 29889, 32001,  3323,   622, 29901, 17778, 29888,  2152,\n",
              "          6225, 11763,   363,   278, 19906,   292,   341,   728,   481,    13,\n",
              "            13,    13, 29928,   799]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(3323))\n",
        "print(tokenizer.decode(622))\n",
        "print(tokenizer.decode([3323, 622]))\n",
        "print(tokenizer.decode(29901))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erAHKXklUZ6B",
        "outputId": "d79524d1-940b-499f-f3fd-e98a086b3ca4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub\n",
            "ject\n",
            "Subject\n",
            ":\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Trained LLM Tokenizers"
      ],
      "metadata": {
        "id": "z8QnNjerUulx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "colors_list = [\n",
        "'102;194;165', '252;141;98', '141;160;203',\n",
        "'231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "\n",
        "def show_tokens(sentence, tokenizer_name):\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "  token_ids = tokenizer(sentence).input_ids\n",
        "  for idx, t in enumerate(token_ids):\n",
        "    print(\n",
        "        f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "        tokenizer.decode(t) +\n",
        "        '\\x1b[0m',\n",
        "        end=' '\n",
        "    )"
      ],
      "metadata": {
        "id": "9-MA6Jq7UliJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "ðŸŽµ é¸Ÿ\n",
        "show_tokens False None elif == >= else: two tabs:\"    \" Three tabs: \"       \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "heU8_KfqYVlV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "show_tokens(text, \"bert-base-cased\")"
      ],
      "metadata": {
        "id": "6RoR26LlYWOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"gpt2\")"
      ],
      "metadata": {
        "id": "D48o-HMCYXdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"google/flan-t5-small\")\n"
      ],
      "metadata": {
        "id": "6o6FS6ZyYhRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The official is `tiktoken` but this the same tokenizer on the HF platform\n",
        "show_tokens(text, \"Xenova/gpt-4\")"
      ],
      "metadata": {
        "id": "6yMBk5V2YlZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"bigcode/starcoder2-15b\")"
      ],
      "metadata": {
        "id": "F1zKqJb-Yvb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"facebook/galactica-1.3b\")"
      ],
      "metadata": {
        "id": "d1QtcsPQYyo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"
      ],
      "metadata": {
        "id": "gwHRYWYLY779"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contextualized Word Embeddings From a Language Model (Like BERT)"
      ],
      "metadata": {
        "id": "W0yeuBXq3g3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# load a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "# load a language model\n",
        "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
        "\n",
        "# tokenize the sentence\n",
        "tokens = tokenizer('Hello world', return_tensors='pt')\n",
        "\n",
        "# process the tokens\n",
        "output = model(**tokens)[0]"
      ],
      "metadata": {
        "id": "TfWIf2aNY-Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5sLa72t5Io_",
        "outputId": "ee403e33-e160-468a-90fb-507d540044bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 384])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in tokens['input_ids'][0]:\n",
        "  print(tokenizer.decode(token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhqsJH845Of_",
        "outputId": "7aa574ad-8830-46ed-fff7-2a90971ee693"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "Hello\n",
            " world\n",
            "[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9FRqlzQ5gAn",
        "outputId": "f3253e90-114c-4d55-8a64-e0a8914d7b33"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.4816,  0.0861, -0.1819,  ..., -0.0612, -0.3911,  0.3017],\n",
              "         [ 0.1898,  0.3208, -0.2315,  ...,  0.3714,  0.2478,  0.8048],\n",
              "         [ 0.2071,  0.5036, -0.0485,  ...,  1.2175, -0.2292,  0.8582],\n",
              "         [-3.4278,  0.0645, -0.1427,  ...,  0.0658, -0.4367,  0.3834]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Embeddings (For Sentences and Whole Documents)"
      ],
      "metadata": {
        "id": "92ZqsqTF5rdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "vector = model.encode('Best movie ever!')"
      ],
      "metadata": {
        "id": "wD1r9BXs5k7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YKGMxmH6Y0e",
        "outputId": "7f917bd0-4e45-4359-d9f5-2488d87ebcbc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings Beyond LLMs"
      ],
      "metadata": {
        "id": "0_Nw3vzC6sn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LXlx0wJ6x27",
        "outputId": "c64a34d2-0f75-426b-dcbe-b9ef7d4f33b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Download embeddings (66MB, glove, trained on wikipedia, vector size: 50)\n",
        "# Other options include \"word2vec-google-news-300\"\n",
        "# More options at https://github.com/RaRe-Technologies/gensim-data\n",
        "model = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss1iVJ-16og-",
        "outputId": "a670ba0e-39fd-48bc-846b-e266d76d347a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar([model['king']], topn=11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4rPgj4r6vNW",
        "outputId": "f037bb9e-c6f6-4669-a167-29bee5dbe49e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 1.0000001192092896),\n",
              " ('prince', 0.8236179351806641),\n",
              " ('queen', 0.7839043140411377),\n",
              " ('ii', 0.7746230363845825),\n",
              " ('emperor', 0.7736247777938843),\n",
              " ('son', 0.766719400882721),\n",
              " ('uncle', 0.7627150416374207),\n",
              " ('kingdom', 0.7542161345481873),\n",
              " ('throne', 0.7539914846420288),\n",
              " ('brother', 0.7492411136627197),\n",
              " ('ruler', 0.7434253692626953)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommending songs by embeddings"
      ],
      "metadata": {
        "id": "Z_DMa4-G7Ogo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from urllib import request\n",
        "\n",
        "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
        "lines = data.read().decode(\"utf-8\").split('\\n')[2:]\n",
        "\n",
        "playlists = [s.rstrip().split() for s in lines if len(s.split())>1]\n",
        "\n",
        "# Load song metadata\n",
        "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
        "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
        "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
        "songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n",
        "songs_df = songs_df.set_index('id')"
      ],
      "metadata": {
        "id": "_KVBqdPF7LTm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( 'Playlist #1:\\n ', playlists[0], '\\n')\n",
        "print( 'Playlist #2:\\n ', playlists[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ylQsVAc8QLs",
        "outputId": "617a1d5d-063e-4de8-f8e9-05339a0760d0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Playlist #1:\n",
            "  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '2', '42', '43', '44', '45', '46', '47', '48', '20', '49', '8', '50', '51', '52', '53', '54', '55', '56', '57', '25', '58', '59', '60', '61', '62', '3', '63', '64', '65', '66', '46', '47', '67', '2', '48', '68', '69', '70', '57', '50', '71', '72', '53', '73', '25', '74', '59', '20', '46', '75', '76', '77', '59', '20', '43'] \n",
            "\n",
            "Playlist #2:\n",
            "  ['78', '79', '80', '3', '62', '81', '14', '82', '48', '83', '84', '17', '85', '86', '87', '88', '74', '89', '90', '91', '4', '73', '62', '92', '17', '53', '59', '93', '94', '51', '50', '27', '95', '48', '96', '97', '98', '99', '100', '57', '101', '102', '25', '103', '3', '104', '105', '106', '107', '47', '108', '109', '110', '111', '112', '113', '25', '63', '62', '114', '115', '84', '116', '117', '118', '119', '120', '121', '122', '123', '50', '70', '71', '124', '17', '85', '14', '82', '48', '125', '47', '46', '72', '53', '25', '73', '4', '126', '59', '74', '20', '43', '127', '128', '129', '13', '82', '48', '130', '131', '132', '133', '134', '135', '136', '137', '59', '46', '138', '43', '20', '139', '140', '73', '57', '70', '141', '3', '1', '74', '142', '143', '144', '145', '48', '13', '25', '146', '50', '147', '126', '59', '20', '148', '149', '150', '151', '152', '56', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '60', '176', '51', '177', '178', '179', '180', '181', '182', '183', '184', '185', '57', '186', '187', '188', '189', '190', '191', '46', '192', '193', '194', '195', '196', '197', '198', '25', '199', '200', '49', '201', '100', '202', '203', '204', '205', '206', '207', '32', '208', '209', '210']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train our Word2Vec model\n",
        "model = Word2Vec(\n",
        "    playlists, vector_size=32, window=20, negative=50, min_count=1, workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "HcbXY9bw8Xfc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "song_id = 2172\n",
        "\n",
        "# Ask the model for songs similar to song #2172\n",
        "model.wv.most_similar(positive=str(song_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4nsw2BV8bQL",
        "outputId": "dd02b173-bc62-442b-d00c-bb382393176f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1922', 0.9980372786521912),\n",
              " ('11473', 0.9977210164070129),\n",
              " ('6626', 0.9965317845344543),\n",
              " ('2104', 0.9953141212463379),\n",
              " ('6641', 0.9950987100601196),\n",
              " ('5634', 0.9948092103004456),\n",
              " ('5586', 0.9946373105049133),\n",
              " ('2014', 0.9943349361419678),\n",
              " ('6658', 0.9936967492103577),\n",
              " ('5549', 0.9934738278388977)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(songs_df.iloc[2172])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWzUS44Z8pLu",
        "outputId": "a08dd223-befe-4ea1-99eb-4aa118997240"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title     Fade To Black\n",
            "artist        Metallica\n",
            "Name: 2172 , dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def print_recommendations(song_id):\n",
        "    similar_songs = np.array(\n",
        "        model.wv.most_similar(positive=str(song_id),topn=5)\n",
        "    )[:,0]\n",
        "    return  songs_df.iloc[similar_songs]\n",
        "\n",
        "# Extract recommendations\n",
        "print_recommendations(2172)"
      ],
      "metadata": {
        "id": "TGjuU_Ea8qvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_recommendations(2172)"
      ],
      "metadata": {
        "id": "Cke9-EAy8sQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_recommendations(842)"
      ],
      "metadata": {
        "id": "Go9FLH6L8uE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTSiX6mZ9C2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}